{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install pandas networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "data = pd.read_excel('scraped_text_v1.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Authorship Network Analysis ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_analyze_visualize_coauthorship_graph(dataframe, authors_column):\n",
    "    # Initialize an empty graph\n",
    "    G_coauthorship = nx.Graph()\n",
    "    \n",
    "    # Iterate over the dataset to extract authors and create edges\n",
    "    for authors in dataframe[authors_column]:\n",
    "        author_list = [author.strip() for author in authors.split(',')]\n",
    "        for pair in itertools.combinations(author_list, 2):\n",
    "            G_coauthorship.add_edge(pair[0], pair[1])\n",
    "    \n",
    "    # Display the number of nodes and edges in the co-authorship network\n",
    "    num_nodes = G_coauthorship.number_of_nodes()\n",
    "    num_edges = G_coauthorship.number_of_edges()\n",
    "    print(f\"Co-authorship Network: {num_nodes} nodes, {num_edges} edges\")\n",
    "    \n",
    "    # Visualize the co-authorship network\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G_coauthorship, k=0.3)\n",
    "    nx.draw(G_coauthorship, pos, with_labels=True, node_size=50, font_size=8, font_color='darkblue', node_color='skyblue', edge_color='gray')\n",
    "    plt.title('Co-authorship Network')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute centrality measures for the co-authorship network\n",
    "    degree_centrality = nx.degree_centrality(G_coauthorship)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G_coauthorship)\n",
    "    closeness_centrality = nx.closeness_centrality(G_coauthorship)\n",
    "    \n",
    "    # Create a DataFrame to display the top authors based on centrality measures\n",
    "    centrality_df = pd.DataFrame({\n",
    "        'Author': list(degree_centrality.keys()),\n",
    "        'Degree Centrality': list(degree_centrality.values()),\n",
    "        'Betweenness Centrality': list(betweenness_centrality.values()),\n",
    "        'Closeness Centrality': list(closeness_centrality.values())\n",
    "    })\n",
    "    top_authors = centrality_df.sort_values(by='Degree Centrality', ascending=False).head(10)\n",
    "    print(\"Top Authors by Degree Centrality:\")\n",
    "    print(top_authors)\n",
    "    \n",
    "    return G_coauthorship, centrality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create, analyze, and visualize the co-authorship graph using the function\n",
    "coauthorship_graph, centrality_df = create_analyze_visualize_coauthorship_graph(data, 'Author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Keyword Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def create_analyze_visualize_keyword_network(dataframe, keywords_column):\n",
    "    # Initialize a graph for the keyword co-occurrence network\n",
    "    G_keywords = nx.Graph()\n",
    "    \n",
    "    # Iterate over the dataset to extract keywords and create edges\n",
    "    for keywords in dataframe[keywords_column]:\n",
    "        if pd.isna(keywords):\n",
    "            continue\n",
    "        keyword_list = [keyword.strip() for keyword in keywords.split(',')]\n",
    "        for pair in itertools.combinations(keyword_list, 2):\n",
    "            G_keywords.add_edge(pair[0], pair[1])\n",
    "    \n",
    "    # Display the number of nodes and edges in the keyword co-occurrence network\n",
    "    num_nodes_keywords = G_keywords.number_of_nodes()\n",
    "    num_edges_keywords = G_keywords.number_of_edges()\n",
    "    print(f\"Keyword Co-occurrence Network: {num_nodes_keywords} nodes, {num_edges_keywords} edges\")\n",
    "    \n",
    "    # Visualize the keyword co-occurrence network\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G_keywords, k=0.3)\n",
    "    nx.draw(G_keywords, pos, with_labels=True, node_size=50, font_size=8, font_color='darkgreen', node_color='lightgreen', edge_color='gray')\n",
    "    plt.title('Keyword Co-occurrence Network')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute centrality measures for the keyword network\n",
    "    degree_centrality_keywords = nx.degree_centrality(G_keywords)\n",
    "    betweenness_centrality_keywords = nx.betweenness_centrality(G_keywords)\n",
    "    closeness_centrality_keywords = nx.closeness_centrality(G_keywords)\n",
    "    \n",
    "    # Create a DataFrame to display the top keywords based on centrality measures\n",
    "    centrality_keywords_df = pd.DataFrame({\n",
    "        'Keyword': list(degree_centrality_keywords.keys()),\n",
    "        'Degree Centrality': list(degree_centrality_keywords.values()),\n",
    "        'Betweenness Centrality': list(betweenness_centrality_keywords.values()),\n",
    "        'Closeness Centrality': list(closeness_centrality_keywords.values())\n",
    "    })\n",
    "    top_keywords = centrality_keywords_df.sort_values(by='Degree Centrality', ascending=False).head(10)\n",
    "    print(\"Top Keywords by Degree Centrality:\")\n",
    "    print(top_keywords)\n",
    "    \n",
    "    return G_keywords, centrality_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create, analyze, and visualize the keyword co-occurrence network using the function\n",
    "keyword_network, centrality_keywords_df = create_analyze_visualize_keyword_network(data, 'Keywords')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
